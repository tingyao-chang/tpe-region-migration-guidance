# AWS è·¨å€åŸŸå·¥ä½œè² è¼‰é·ç§»éƒ¨ç½²æŒ‡å—

## æ¦‚è¿°

æœ¬æŒ‡å—æä¾› NRT Region â†’ TPE Region é·ç§»çš„å…·é«”åŸ·è¡Œå‘½ä»¤å’Œè…³æœ¬ï¼ŒåŒ…å« EKSã€ECSã€EC2 ä¸‰ç¨®è¨ˆç®—æœå‹™çš„å®Œæ•´é·ç§»æµç¨‹ã€‚

## å‰ç½®æº–å‚™

### ç’°å¢ƒè®Šæ•¸è¨­å®š

```bash
#!/bin/bash
# config.sh - è¨­å®šç’°å¢ƒè®Šæ•¸
export SOURCE_REGION="ap-northeast-1"
export TARGET_REGION="ap-east-2"
export AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
export CLUSTER_NAME="your-cluster"
export DB_INSTANCE_ID="your-db-instance"

# è¼‰å…¥è¨­å®š
source config.sh
```

## ECR è·¨å€åŸŸè¤‡è£½ï¼ˆæ‰€æœ‰æ¡ˆä¾‹é€šç”¨ï¼‰

### è¨­å®šè‡ªå‹•è¤‡è£½è¦å‰‡

```bash
#!/bin/bash
# setup_ecr_replication.sh
source config.sh

echo "ğŸ”„ è¨­å®š ECR è·¨å€åŸŸè¤‡è£½è¦å‰‡..."

aws ecr put-replication-configuration \
  --replication-configuration '{
    "rules": [
      {
        "destinations": [
          {
            "region": "'$TARGET_REGION'",
            "registryId": "'$AWS_ACCOUNT_ID'"
          }
        ],
        "repositoryFilters": [
          {
            "filter": "*",
            "filterType": "PREFIX_MATCH"
          }
        ]
      }
    ]
  }' \
  --region $SOURCE_REGION

echo "âœ… ECR è·¨å€åŸŸè¤‡è£½è¦å‰‡è¨­å®šå®Œæˆï¼"

# é©—è­‰è¤‡è£½ç‹€æ…‹
echo "ğŸ” é©—è­‰æ˜ åƒè¤‡è£½ç‹€æ…‹..."
sleep 30
aws ecr describe-repositories --region $TARGET_REGION --query 'repositories[].repositoryName' --output table
```

### ECR è¤‡è£½é©—è­‰

```bash
#!/bin/bash
# verify_ecr_replication.sh
source config.sh

echo "ğŸ” é©—è­‰ ECR æ˜ åƒè¤‡è£½ç‹€æ…‹..."

echo "ä¾†æºå€åŸŸ ($SOURCE_REGION) çš„å„²å­˜åº«ï¼š"
aws ecr describe-repositories --region $SOURCE_REGION --query 'repositories[].repositoryName' --output table

echo "ç›®æ¨™å€åŸŸ ($TARGET_REGION) çš„å„²å­˜åº«ï¼š"
aws ecr describe-repositories --region $TARGET_REGION --query 'repositories[].repositoryName' --output table

# æ¯”è¼ƒæ˜ åƒæ¨™ç±¤
for repo in $(aws ecr describe-repositories --region $SOURCE_REGION --query 'repositories[].repositoryName' --output text); do
    echo "æª¢æŸ¥å„²å­˜åº«: $repo"
    echo "ä¾†æºå€åŸŸæ˜ åƒï¼š"
    aws ecr list-images --repository-name $repo --region $SOURCE_REGION --query 'imageIds[].imageTag' --output table
    echo "ç›®æ¨™å€åŸŸæ˜ åƒï¼š"
    aws ecr list-images --repository-name $repo --region $TARGET_REGION --query 'imageIds[].imageTag' --output table
    echo "---"
done
```

## æ¡ˆä¾‹ä¸€ï¼šEKS å¢é›†å®Œæ•´é·ç§»

### æ¬é·æ­¥é©Ÿé †åº
1. **Week 1**: è¨­å®š ECR è·¨å€åŸŸè¤‡è£½ï¼ˆèƒŒæ™¯åŸ·è¡Œï¼‰
2. **Week 2**: åŒ¯å‡º EKS å¢é›†è¨­å®š â†’ ä¿®æ”¹å€åŸŸåƒæ•¸ â†’ éƒ¨ç½²åˆ° TPE Region
3. **Week 3**: RDS å¿«ç…§é·ç§» + DMS å·®ç•°åŒæ­¥ + Kubernetes æ‡‰ç”¨ç¨‹å¼éƒ¨ç½²
4. **Week 4**: æ¸¬è©¦é©—è­‰ + DNS æµé‡åˆ‡æ›

### 1. åŒ¯å‡º EKS å¢é›†è¨­å®š

```bash
#!/bin/bash
# export_eks_config.sh
source config.sh

echo "ğŸ“¤ åŒ¯å‡º EKS å¢é›†è¨­å®š..."

# 1. åŒ¯å‡ºå¢é›†åŸºæœ¬è¨­å®š
aws eks describe-cluster \
  --name $CLUSTER_NAME \
  --region $SOURCE_REGION \
  --query 'cluster.{name:name,version:version,roleArn:roleArn,resourcesVpcConfig:resourcesVpcConfig,logging:logging,encryptionConfig:encryptionConfig,tags:tags}' \
  > eks-cluster-config.json

# 2. åŒ¯å‡ºç¯€é»ç¾¤çµ„è¨­å®š
aws eks list-nodegroups \
  --cluster-name $CLUSTER_NAME \
  --region $SOURCE_REGION \
  --query 'nodegroups' \
  --output text | while read nodegroup; do
    echo "åŒ¯å‡ºç¯€é»ç¾¤çµ„: $nodegroup"
    aws eks describe-nodegroup \
      --cluster-name $CLUSTER_NAME \
      --nodegroup-name $nodegroup \
      --region $SOURCE_REGION \
      --query 'nodegroup.{nodegroupName:nodegroupName,scalingConfig:scalingConfig,instanceTypes:instanceTypes,amiType:amiType,capacityType:capacityType,diskSize:diskSize,nodeRole:nodeRole,subnets:subnets,remoteAccess:remoteAccess,labels:labels,tags:tags}' \
      > "nodegroup-${nodegroup}-config.json"
done

# 3. åŒ¯å‡ºé™„åŠ å…ƒä»¶è¨­å®š
aws eks list-addons \
  --cluster-name $CLUSTER_NAME \
  --region $SOURCE_REGION \
  --query 'addons' \
  --output text | while read addon; do
    echo "åŒ¯å‡ºé™„åŠ å…ƒä»¶: $addon"
    aws eks describe-addon \
      --cluster-name $CLUSTER_NAME \
      --addon-name $addon \
      --region $SOURCE_REGION \
      --query 'addon.{addonName:addonName,addonVersion:addonVersion,serviceAccountRoleArn:serviceAccountRoleArn,configurationValues:configurationValues,tags:tags}' \
      > "addon-${addon}-config.json"
done

echo "âœ… EKS è¨­å®šåŒ¯å‡ºå®Œæˆï¼"
```

### 2. ä¿®æ”¹å€åŸŸç‰¹å®šè¨­å®š

```bash
#!/bin/bash
# modify_eks_config.sh
source config.sh

echo "ğŸ”§ ä¿®æ”¹å€åŸŸç‰¹å®šè¨­å®š..."

# ç²å–ç›®æ¨™å€åŸŸçš„ VPC è³‡æº
TARGET_VPC_ID=$(aws ec2 describe-vpcs --filters "Name=tag:Name,Values=your-vpc" --query 'Vpcs[0].VpcId' --output text --region $TARGET_REGION)
TARGET_SUBNET_IDS=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$TARGET_VPC_ID" --query 'Subnets[].SubnetId' --output text --region $TARGET_REGION)
TARGET_SECURITY_GROUP_ID=$(aws ec2 describe-security-groups --filters "Name=vpc-id,Values=$TARGET_VPC_ID" "Name=group-name,Values=eks-cluster-sg" --query 'SecurityGroups[0].GroupId' --output text --region $TARGET_REGION)

# æ›´æ–°å¢é›†è¨­å®šæª”
jq --arg subnets "$(echo $TARGET_SUBNET_IDS | tr ' ' ',')" \
   --arg sg "$TARGET_SECURITY_GROUP_ID" \
   '.resourcesVpcConfig.subnetIds = ($subnets | split(",")) | 
    .resourcesVpcConfig.securityGroupIds = [$sg]' \
   eks-cluster-config.json > eks-cluster-config-modified.json

# ä¿®æ”¹ç¯€é»ç¾¤çµ„è¨­å®šä¸­çš„å­ç¶²è·¯
for nodegroup_file in nodegroup-*-config.json; do
    if [ -f "$nodegroup_file" ]; then
        echo "ä¿®æ”¹ $nodegroup_file"
        jq --arg subnets "$(echo $TARGET_SUBNET_IDS | tr ' ' ',')" \
           '.subnets = ($subnets | split(","))' \
           "$nodegroup_file" > "${nodegroup_file%.json}-modified.json"
    fi
done

echo "âœ… è¨­å®šä¿®æ”¹å®Œæˆï¼"
```

### 3. éƒ¨ç½²åˆ° TPE Region

```bash
#!/bin/bash
# deploy_eks_cluster.sh
source config.sh

echo "ğŸš€ åœ¨ TPE Region éƒ¨ç½² EKS å¢é›†..."

# 1. å»ºç«‹ EKS å¢é›†
CLUSTER_CONFIG=$(cat eks-cluster-config-modified.json)
aws eks create-cluster \
  --region $TARGET_REGION \
  --name $CLUSTER_NAME \
  --version $(echo $CLUSTER_CONFIG | jq -r '.version') \
  --role-arn $(echo $CLUSTER_CONFIG | jq -r '.roleArn') \
  --resources-vpc-config "$(echo $CLUSTER_CONFIG | jq -c '.resourcesVpcConfig')" \
  --logging "$(echo $CLUSTER_CONFIG | jq -c '.logging // {}')" \
  --tags "$(echo $CLUSTER_CONFIG | jq -c '.tags // {}')"

# ç­‰å¾…å¢é›†å»ºç«‹å®Œæˆ
echo "â³ ç­‰å¾… EKS å¢é›†å»ºç«‹å®Œæˆ..."
aws eks wait cluster-active --name $CLUSTER_NAME --region $TARGET_REGION

# 2. å»ºç«‹ç¯€é»ç¾¤çµ„
for nodegroup_file in nodegroup-*-modified.json; do
    if [ -f "$nodegroup_file" ]; then
        echo "å»ºç«‹ç¯€é»ç¾¤çµ„: $nodegroup_file"
        NODEGROUP_CONFIG=$(cat "$nodegroup_file")
        NODEGROUP_NAME=$(echo $NODEGROUP_CONFIG | jq -r '.nodegroupName')
        
        aws eks create-nodegroup \
          --region $TARGET_REGION \
          --cluster-name $CLUSTER_NAME \
          --nodegroup-name $NODEGROUP_NAME \
          --scaling-config "$(echo $NODEGROUP_CONFIG | jq -c '.scalingConfig')" \
          --instance-types "$(echo $NODEGROUP_CONFIG | jq -r '.instanceTypes[]')" \
          --ami-type "$(echo $NODEGROUP_CONFIG | jq -r '.amiType')" \
          --capacity-type "$(echo $NODEGROUP_CONFIG | jq -r '.capacityType // "ON_DEMAND"')" \
          --disk-size "$(echo $NODEGROUP_CONFIG | jq -r '.diskSize // 20')" \
          --node-role "$(echo $NODEGROUP_CONFIG | jq -r '.nodeRole')" \
          --subnets "$(echo $NODEGROUP_CONFIG | jq -r '.subnets[]')" \
          --labels "$(echo $NODEGROUP_CONFIG | jq -c '.labels // {}')" \
          --tags "$(echo $NODEGROUP_CONFIG | jq -c '.tags // {}')"
        
        # ç­‰å¾…ç¯€é»ç¾¤çµ„å»ºç«‹å®Œæˆ
        aws eks wait nodegroup-active --cluster-name $CLUSTER_NAME --nodegroup-name $NODEGROUP_NAME --region $TARGET_REGION
    fi
done

# 3. å®‰è£é™„åŠ å…ƒä»¶
for addon_file in addon-*-config.json; do
    if [ -f "$addon_file" ]; then
        echo "å®‰è£é™„åŠ å…ƒä»¶: $addon_file"
        ADDON_CONFIG=$(cat "$addon_file")
        ADDON_NAME=$(echo $ADDON_CONFIG | jq -r '.addonName')
        
        aws eks create-addon \
          --region $TARGET_REGION \
          --cluster-name $CLUSTER_NAME \
          --addon-name $ADDON_NAME \
          --addon-version "$(echo $ADDON_CONFIG | jq -r '.addonVersion')" \
          --service-account-role-arn "$(echo $ADDON_CONFIG | jq -r '.serviceAccountRoleArn // empty')" \
          --configuration-values "$(echo $ADDON_CONFIG | jq -r '.configurationValues // empty')" \
          --tags "$(echo $ADDON_CONFIG | jq -c '.tags // {}')"
    fi
done

echo "âœ… EKS å¢é›†éƒ¨ç½²å®Œæˆï¼"
```

## æ¡ˆä¾‹äºŒï¼šECS å¢é›†å®Œæ•´é·ç§»

### æ¬é·æ­¥é©Ÿé †åº
1. **Week 1**: è¨­å®š ECR è·¨å€åŸŸè¤‡è£½ï¼ˆèƒŒæ™¯åŸ·è¡Œï¼‰
2. **Week 2**: åŒ¯å‡º ECS å¢é›†è¨­å®š â†’ è‡ªå‹•ä¿®æ”¹æ˜ åƒè·¯å¾‘ â†’ éƒ¨ç½²åˆ° TPE Region
3. **Week 3**: RDS å¿«ç…§é·ç§» + DMS å·®ç•°åŒæ­¥ + ECS æœå‹™éƒ¨ç½²
4. **Week 4**: æ¸¬è©¦é©—è­‰ + DNS æµé‡åˆ‡æ›

### 1. åŒ¯å‡º ECS è¨­å®š

```bash
#!/bin/bash
# export_ecs_config.sh
source config.sh

echo "ğŸ“¤ åŒ¯å‡º ECS å¢é›†è¨­å®š..."

# 1. åŒ¯å‡ºå¢é›†è¨­å®š
aws ecs describe-clusters \
  --clusters $CLUSTER_NAME \
  --region $SOURCE_REGION \
  --query 'clusters[0].{clusterName:clusterName,tags:tags,settings:settings,configuration:configuration,capacityProviders:capacityProviders,defaultCapacityProviderStrategy:defaultCapacityProviderStrategy}' \
  > ecs-cluster-config.json

# 2. åŒ¯å‡ºæ‰€æœ‰æœå‹™è¨­å®š
aws ecs list-services \
  --cluster $CLUSTER_NAME \
  --region $SOURCE_REGION \
  --query 'serviceArns' \
  --output text | while read service_arn; do
    service_name=$(basename $service_arn)
    echo "åŒ¯å‡ºæœå‹™: $service_name"
    
    aws ecs describe-services \
      --cluster $CLUSTER_NAME \
      --services $service_name \
      --region $SOURCE_REGION \
      --query 'services[0].{serviceName:serviceName,taskDefinition:taskDefinition,desiredCount:desiredCount,launchType:launchType,platformVersion:platformVersion,networkConfiguration:networkConfiguration,loadBalancers:loadBalancers,serviceRegistries:serviceRegistries,tags:tags,enableExecuteCommand:enableExecuteCommand,capacityProviderStrategy:capacityProviderStrategy}' \
      > "service-${service_name}-config.json"
done

# 3. åŒ¯å‡ºä»»å‹™å®šç¾©
aws ecs list-task-definitions \
  --family-prefix your-app \
  --region $SOURCE_REGION \
  --query 'taskDefinitionArns[-1]' \
  --output text | while read task_def_arn; do
    task_def_name=$(basename $task_def_arn | cut -d':' -f1)
    echo "åŒ¯å‡ºä»»å‹™å®šç¾©: $task_def_name"
    
    aws ecs describe-task-definition \
      --task-definition $task_def_arn \
      --region $SOURCE_REGION \
      --query 'taskDefinition | del(.taskDefinitionArn, .revision, .status, .requiresAttributes, .registeredAt, .registeredBy, .compatibilities)' \
      > "taskdef-${task_def_name}-config.json"
done

echo "âœ… ECS è¨­å®šåŒ¯å‡ºå®Œæˆï¼"
```

### 2. éƒ¨ç½² ECS å¢é›†

```bash
#!/bin/bash
# deploy_ecs_cluster.sh
source config.sh

echo "ğŸš€ åœ¨ TPE Region éƒ¨ç½² ECS å¢é›†..."

# 1. å»ºç«‹ ECS å¢é›†
CLUSTER_CONFIG=$(cat ecs-cluster-config.json)
aws ecs create-cluster \
  --region $TARGET_REGION \
  --cluster-name $CLUSTER_NAME \
  --tags "$(echo $CLUSTER_CONFIG | jq -c '.tags // []')" \
  --settings "$(echo $CLUSTER_CONFIG | jq -c '.settings // []')" \
  --configuration "$(echo $CLUSTER_CONFIG | jq -c '.configuration // {}')"

# 2. è¨»å†Šä»»å‹™å®šç¾©ï¼ˆè‡ªå‹•ä¿®æ”¹æ˜ åƒ URI å’Œè³‡æ–™åº«é€£ç·šï¼‰
for taskdef_file in taskdef-*-config.json; do
    if [ -f "$taskdef_file" ]; then
        echo "è¨»å†Šä»»å‹™å®šç¾©: $taskdef_file"
        
        # ä¿®æ”¹å®¹å™¨æ˜ åƒ URI å’Œç’°å¢ƒè®Šæ•¸
        jq '.containerDefinitions[].image |= sub("ap-northeast-1"; "ap-east-2") |
            .containerDefinitions[].environment[]? |= if .name == "DB_HOST" then .value |= sub("'$DB_INSTANCE_ID'"; "'$DB_INSTANCE_ID'-tpe") else . end' \
           "$taskdef_file" > "${taskdef_file%.json}-modified.json"
        
        aws ecs register-task-definition \
          --region $TARGET_REGION \
          --cli-input-json file://"${taskdef_file%.json}-modified.json"
    fi
done

# 3. å»ºç«‹æœå‹™ï¼ˆè‡ªå‹•ä¿®æ”¹ç¶²è·¯è¨­å®šï¼‰
TARGET_VPC_ID=$(aws ec2 describe-vpcs --filters "Name=tag:Name,Values=your-vpc" --query 'Vpcs[0].VpcId' --output text --region $TARGET_REGION)
TARGET_SUBNET_IDS=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$TARGET_VPC_ID" --query 'Subnets[].SubnetId' --output text --region $TARGET_REGION)
TARGET_SECURITY_GROUP_ID=$(aws ec2 describe-security-groups --filters "Name=vpc-id,Values=$TARGET_VPC_ID" --query 'SecurityGroups[0].GroupId' --output text --region $TARGET_REGION)

for service_file in service-*-config.json; do
    if [ -f "$service_file" ]; then
        echo "å»ºç«‹æœå‹™: $service_file"
        
        # ä¿®æ”¹ç¶²è·¯è¨­å®š
        jq --arg subnets "$(echo $TARGET_SUBNET_IDS | tr ' ' ',')" \
           --arg sg "$TARGET_SECURITY_GROUP_ID" \
           '.networkConfiguration.awsvpcConfiguration.subnets = ($subnets | split(",")) | 
            .networkConfiguration.awsvpcConfiguration.securityGroups = [$sg]' \
           "$service_file" > "${service_file%.json}-modified.json"
        
        SERVICE_CONFIG=$(cat "${service_file%.json}-modified.json")
        SERVICE_NAME=$(echo $SERVICE_CONFIG | jq -r '.serviceName')
        
        aws ecs create-service \
          --region $TARGET_REGION \
          --cluster $CLUSTER_NAME \
          --service-name $SERVICE_NAME \
          --task-definition "$(echo $SERVICE_CONFIG | jq -r '.taskDefinition')" \
          --desired-count "$(echo $SERVICE_CONFIG | jq -r '.desiredCount')" \
          --launch-type "$(echo $SERVICE_CONFIG | jq -r '.launchType')" \
          --platform-version "$(echo $SERVICE_CONFIG | jq -r '.platformVersion // "LATEST"')" \
          --network-configuration "$(echo $SERVICE_CONFIG | jq -c '.networkConfiguration')" \
          --load-balancers "$(echo $SERVICE_CONFIG | jq -c '.loadBalancers // []')" \
          --service-registries "$(echo $SERVICE_CONFIG | jq -c '.serviceRegistries // []')" \
          --tags "$(echo $SERVICE_CONFIG | jq -c '.tags // []')" \
          --enable-execute-command "$(echo $SERVICE_CONFIG | jq -r '.enableExecuteCommand // false')"
        
        # ç­‰å¾…æœå‹™ç©©å®š
        aws ecs wait services-stable --cluster $CLUSTER_NAME --services $SERVICE_NAME --region $TARGET_REGION
    fi
done

### 4. Kubernetes æ‡‰ç”¨ç¨‹å¼é·ç§»

```bash
#!/bin/bash
# migrate_k8s_apps.sh
source config.sh

SOURCE_CLUSTER_CONTEXT="arn:aws:eks:$SOURCE_REGION:$AWS_ACCOUNT_ID:cluster/$CLUSTER_NAME"
TARGET_CLUSTER_CONTEXT="arn:aws:eks:$TARGET_REGION:$AWS_ACCOUNT_ID:cluster/$CLUSTER_NAME"
NAMESPACE="default"

echo "ğŸš€ é·ç§» Kubernetes æ‡‰ç”¨ç¨‹å¼..."

# 1. è¨­å®š kubectl context
kubectl config use-context $SOURCE_CLUSTER_CONTEXT
kubectl config rename-context $SOURCE_CLUSTER_CONTEXT source-cluster

kubectl config use-context $TARGET_CLUSTER_CONTEXT  
kubectl config rename-context $TARGET_CLUSTER_CONTEXT target-cluster

# 2. åŒ¯å‡ºæ‰€æœ‰æ‡‰ç”¨ç¨‹å¼è³‡æº
echo "ğŸ“¤ åŒ¯å‡º Kubernetes è³‡æº..."
kubectl --context=source-cluster get deployments,services,configmaps,secrets,ingresses,persistentvolumeclaims \
  -n $NAMESPACE -o yaml > k8s-resources-export.yaml

# 3. è‡ªå‹•ä¿®æ”¹æ˜ åƒè·¯å¾‘å’Œè³‡æ–™åº«é€£ç·š
echo "ğŸ”§ ä¿®æ”¹å®¹å™¨æ˜ åƒè·¯å¾‘å’Œè³‡æ–™åº«è¨­å®š..."
sed "s/ap-northeast-1/ap-east-2/g" k8s-resources-export.yaml | \
sed "s/${DB_INSTANCE_ID}/${DB_INSTANCE_ID}-tpe/g" > k8s-resources-modified.yaml

# 4. éƒ¨ç½²åˆ°ç›®æ¨™å¢é›†
echo "ğŸš€ éƒ¨ç½²åˆ°ç›®æ¨™å¢é›†..."
kubectl --context=target-cluster apply -f k8s-resources-modified.yaml -n $NAMESPACE

# 5. é©—è­‰éƒ¨ç½²
echo "ğŸ” é©—è­‰éƒ¨ç½²ç‹€æ…‹..."
kubectl --context=target-cluster get pods -n $NAMESPACE
kubectl --context=target-cluster get services -n $NAMESPACE

echo "âœ… Kubernetes æ‡‰ç”¨ç¨‹å¼é·ç§»å®Œæˆï¼"
```

## æ¡ˆä¾‹ä¸‰ï¼šEC2 å·¥ä½œè² è¼‰å®Œæ•´é·ç§»

### æ¬é·æ­¥é©Ÿé †åº
1. **Week 1**: å»ºç«‹å’Œè¤‡è£½ AMI + åŸºç¤è¨­æ–½æº–å‚™
2. **Week 2**: å»ºç«‹å•Ÿå‹•ç¯„æœ¬ + Auto Scaling ç¾¤çµ„ + Load Balancer
3. **Week 3**: RDS å¿«ç…§é·ç§» + DMS å·®ç•°åŒæ­¥ + æ‡‰ç”¨ç¨‹å¼é…ç½®æ›´æ–°
4. **Week 4**: æ¸¬è©¦é©—è­‰ + DNS æµé‡åˆ‡æ›

### 1. å»ºç«‹å’Œè¤‡è£½ AMI

```bash
#!/bin/bash
# create_and_copy_ami.sh
source config.sh

INSTANCE_ID="i-1234567890abcdef0"  # æ›¿æ›ç‚ºå¯¦éš›çš„åŸ·è¡Œå€‹é«” ID
AMI_NAME="my-app-ami-$(date +%Y%m%d-%H%M%S)"

echo "ğŸ–¼ï¸ å»ºç«‹å’Œè¤‡è£½ AMI..."

# å¾ä¾†æºå€åŸŸçš„ EC2 åŸ·è¡Œå€‹é«”å»ºç«‹ AMI
aws ec2 create-image \
  --instance-id $INSTANCE_ID \
  --name "$AMI_NAME" \
  --description "Application AMI for TPE migration" \
  --no-reboot \
  --region $SOURCE_REGION

# ç²å–å»ºç«‹çš„ AMI ID
SOURCE_AMI_ID=$(aws ec2 describe-images --owners self --filters "Name=name,Values=$AMI_NAME" --query 'Images[0].ImageId' --output text --region $SOURCE_REGION)

# ç­‰å¾… AMI å»ºç«‹å®Œæˆ
echo "â³ ç­‰å¾… AMI å»ºç«‹å®Œæˆ..."
aws ec2 wait image-available \
  --image-ids $SOURCE_AMI_ID \
  --region $SOURCE_REGION

# è¤‡è£½ AMI åˆ°ç›®æ¨™å€åŸŸ
TARGET_AMI_ID=$(aws ec2 copy-image \
  --source-image-id $SOURCE_AMI_ID \
  --source-region $SOURCE_REGION \
  --name "$AMI_NAME-tpe" \
  --description "Application AMI copied to TPE region" \
  --query 'ImageId' \
  --output text \
  --region $TARGET_REGION)

echo "ä¾†æº AMI ID: $SOURCE_AMI_ID"
echo "ç›®æ¨™ AMI ID: $TARGET_AMI_ID"

# å„²å­˜ AMI ID ä¾›å¾ŒçºŒä½¿ç”¨
echo $TARGET_AMI_ID > target_ami_id.txt

# ç­‰å¾… AMI è¤‡è£½å®Œæˆ
echo "â³ ç­‰å¾… AMI è¤‡è£½å®Œæˆ..."
aws ec2 wait image-available \
  --image-ids $TARGET_AMI_ID \
  --region $TARGET_REGION

echo "âœ… AMI å»ºç«‹å’Œè¤‡è£½å®Œæˆï¼"
```

### 2. å»ºç«‹å•Ÿå‹•ç¯„æœ¬å’Œ Load Balancer

```bash
#!/bin/bash
# setup_ec2_infrastructure.sh
source config.sh

TARGET_AMI_ID=$(cat target_ami_id.txt)

echo "ğŸ—ï¸ å»ºç«‹ EC2 åŸºç¤è¨­æ–½..."

# ç²å–å¿…è¦çš„è³‡æº ID
TARGET_VPC_ID=$(aws ec2 describe-vpcs --filters "Name=tag:Name,Values=your-vpc" --query 'Vpcs[0].VpcId' --output text --region $TARGET_REGION)
PRIVATE_SUBNET_IDS=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$TARGET_VPC_ID" "Name=tag:Type,Values=Private" --query 'Subnets[].SubnetId' --output text --region $TARGET_REGION)
PUBLIC_SUBNET_IDS=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$TARGET_VPC_ID" "Name=tag:Type,Values=Public" --query 'Subnets[].SubnetId' --output text --region $TARGET_REGION)
SECURITY_GROUP_ID=$(aws ec2 describe-security-groups --filters "Name=vpc-id,Values=$TARGET_VPC_ID" "Name=group-name,Values=ec2-app-sg" --query 'SecurityGroups[0].GroupId' --output text --region $TARGET_REGION)
KEY_PAIR_NAME="my-key-pair"  # æ›¿æ›ç‚ºå¯¦éš›çš„é‡‘é‘°å°åç¨±

# æº–å‚™ User Data è…³æœ¬
cat > user-data.sh << EOF
#!/bin/bash
yum update -y
# å®‰è£æ‡‰ç”¨ç¨‹å¼ç›¸ä¾æ€§
yum install -y docker
systemctl start docker
systemctl enable docker

# æ›´æ–°æ‡‰ç”¨ç¨‹å¼è¨­å®šæŒ‡å‘æ–°çš„è³‡æ–™åº«
sed -i 's/${DB_INSTANCE_ID}/${DB_INSTANCE_ID}-tpe/g' /etc/myapp/config.properties
systemctl restart myapp
EOF

# å»ºç«‹å•Ÿå‹•ç¯„æœ¬
aws ec2 create-launch-template \
  --launch-template-name tpe-app-launch-template \
  --launch-template-data "{
    \"ImageId\": \"$TARGET_AMI_ID\",
    \"InstanceType\": \"t3.medium\",
    \"KeyName\": \"$KEY_PAIR_NAME\",
    \"SecurityGroupIds\": [\"$SECURITY_GROUP_ID\"],
    \"UserData\": \"$(base64 -w 0 user-data.sh)\",
    \"IamInstanceProfile\": {
      \"Name\": \"EC2-App-InstanceProfile\"
    },
    \"TagSpecifications\": [{
      \"ResourceType\": \"instance\",
      \"Tags\": [
        {\"Key\": \"Name\", \"Value\": \"tpe-app-instance\"},
        {\"Key\": \"Environment\", \"Value\": \"production\"},
        {\"Key\": \"Project\", \"Value\": \"tpe-migration\"}
      ]
    }]
  }" \
  --region $TARGET_REGION

# å»ºç«‹ Application Load Balancer
ALB_ARN=$(aws elbv2 create-load-balancer \
  --name tpe-ec2-alb \
  --subnets $PUBLIC_SUBNET_IDS \
  --security-groups $SECURITY_GROUP_ID \
  --scheme internet-facing \
  --type application \
  --ip-address-type ipv4 \
  --query 'LoadBalancers[0].LoadBalancerArn' \
  --output text \
  --region $TARGET_REGION)

# å»ºç«‹ç›®æ¨™ç¾¤çµ„
TARGET_GROUP_ARN=$(aws elbv2 create-target-group \
  --name tpe-ec2-targets \
  --protocol HTTP \
  --port 80 \
  --vpc-id $TARGET_VPC_ID \
  --target-type instance \
  --health-check-enabled \
  --health-check-path /health \
  --health-check-interval-seconds 30 \
  --health-check-timeout-seconds 5 \
  --healthy-threshold-count 2 \
  --unhealthy-threshold-count 3 \
  --query 'TargetGroups[0].TargetGroupArn' \
  --output text \
  --region $TARGET_REGION)

# å»ºç«‹ç›£è½å™¨
aws elbv2 create-listener \
  --load-balancer-arn $ALB_ARN \
  --protocol HTTP \
  --port 80 \
  --default-actions Type=forward,TargetGroupArn=$TARGET_GROUP_ARN \
  --region $TARGET_REGION

# å„²å­˜ ARN ä¾›å¾ŒçºŒä½¿ç”¨
echo $ALB_ARN > alb_arn.txt
echo $TARGET_GROUP_ARN > target_group_arn.txt

echo "ALB ARN: $ALB_ARN"
echo "Target Group ARN: $TARGET_GROUP_ARN"
echo "âœ… EC2 åŸºç¤è¨­æ–½å»ºç«‹å®Œæˆï¼"
```

### 3. å»ºç«‹ Auto Scaling ç¾¤çµ„

```bash
#!/bin/bash
# create_autoscaling_group.sh
source config.sh

TARGET_GROUP_ARN=$(cat target_group_arn.txt)

echo "ğŸ“ˆ å»ºç«‹ Auto Scaling ç¾¤çµ„..."

# ç²å–ç§æœ‰å­ç¶²è·¯ IDï¼ˆç”¨æ–¼ EC2 åŸ·è¡Œå€‹é«”ï¼‰
TARGET_VPC_ID=$(aws ec2 describe-vpcs --filters "Name=tag:Name,Values=your-vpc" --query 'Vpcs[0].VpcId' --output text --region $TARGET_REGION)
PRIVATE_SUBNET_IDS=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$TARGET_VPC_ID" "Name=tag:Type,Values=Private" --query 'Subnets[].SubnetId' --output text --region $TARGET_REGION)

# å»ºç«‹ Auto Scaling ç¾¤çµ„
aws autoscaling create-auto-scaling-group \
  --auto-scaling-group-name tpe-app-asg \
  --launch-template "{
    \"LaunchTemplateName\": \"tpe-app-launch-template\",
    \"Version\": \"\$Latest\"
  }" \
  --min-size 2 \
  --max-size 10 \
  --desired-capacity 3 \
  --vpc-zone-identifier "$(echo $PRIVATE_SUBNET_IDS | tr ' ' ',')" \
  --target-group-arns $TARGET_GROUP_ARN \
  --health-check-type ELB \
  --health-check-grace-period 300 \
  --default-cooldown 300 \
  --tags "Key=Name,Value=tpe-app-asg-instance,PropagateAtLaunch=true,ResourceId=tpe-app-asg,ResourceType=auto-scaling-group" \
  --region $TARGET_REGION

# å»ºç«‹æ“´å±•æ”¿ç­–
aws autoscaling put-scaling-policy \
  --auto-scaling-group-name tpe-app-asg \
  --policy-name scale-up-policy \
  --policy-type TargetTrackingScaling \
  --target-tracking-configuration '{
    "TargetValue": 70.0,
    "PredefinedMetricSpecification": {
      "PredefinedMetricType": "ASGAverageCPUUtilization"
    }
  }' \
  --region $TARGET_REGION

# ç­‰å¾…åŸ·è¡Œå€‹é«”å•Ÿå‹•
echo "â³ ç­‰å¾… Auto Scaling ç¾¤çµ„åŸ·è¡Œå€‹é«”å•Ÿå‹•..."
sleep 120

# æª¢æŸ¥ Auto Scaling ç¾¤çµ„ç‹€æ…‹
aws autoscaling describe-auto-scaling-groups \
  --auto-scaling-group-names tpe-app-asg \
  --query 'AutoScalingGroups[0].{DesiredCapacity:DesiredCapacity,MinSize:MinSize,MaxSize:MaxSize,Instances:length(Instances)}' \
  --region $TARGET_REGION

echo "âœ… Auto Scaling ç¾¤çµ„å»ºç«‹å®Œæˆï¼"
```

### 4. é©—è­‰ EC2 éƒ¨ç½²

```bash
#!/bin/bash
# verify_ec2_deployment.sh
source config.sh

ALB_ARN=$(cat alb_arn.txt)
TARGET_GROUP_ARN=$(cat target_group_arn.txt)

echo "ğŸ” é©—è­‰ EC2 éƒ¨ç½²ç‹€æ…‹..."

# æª¢æŸ¥ Auto Scaling ç¾¤çµ„ç‹€æ…‹
echo "Auto Scaling ç¾¤çµ„ç‹€æ…‹ï¼š"
aws autoscaling describe-auto-scaling-groups \
  --auto-scaling-group-names tpe-app-asg \
  --query 'AutoScalingGroups[0].{DesiredCapacity:DesiredCapacity,Instances:Instances[].{InstanceId:InstanceId,HealthStatus:HealthStatus,LifecycleState:LifecycleState}}' \
  --region $TARGET_REGION

# æª¢æŸ¥åŸ·è¡Œå€‹é«”å¥åº·ç‹€æ…‹
INSTANCE_IDS=$(aws autoscaling describe-auto-scaling-groups \
  --auto-scaling-group-names tpe-app-asg \
  --query 'AutoScalingGroups[0].Instances[].InstanceId' \
  --output text \
  --region $TARGET_REGION)

echo "åŸ·è¡Œå€‹é«”è©³ç´°ç‹€æ…‹ï¼š"
aws ec2 describe-instances \
  --instance-ids $INSTANCE_IDS \
  --query 'Reservations[].Instances[].{InstanceId:InstanceId,State:State.Name,InstanceType:InstanceType,LaunchTime:LaunchTime}' \
  --region $TARGET_REGION

# æª¢æŸ¥ Load Balancer ç›®æ¨™å¥åº·
echo "Load Balancer ç›®æ¨™å¥åº·ç‹€æ…‹ï¼š"
aws elbv2 describe-target-health \
  --target-group-arn $TARGET_GROUP_ARN \
  --query 'TargetHealthDescriptions[].{TargetId:Target.Id,HealthStatus:TargetHealth.State,Description:TargetHealth.Description}' \
  --region $TARGET_REGION

# ç²å– ALB DNS åç¨±ä¸¦æ¸¬è©¦æ‡‰ç”¨ç¨‹å¼
ALB_DNS=$(aws elbv2 describe-load-balancers \
  --load-balancer-arns $ALB_ARN \
  --query 'LoadBalancers[0].DNSName' \
  --output text \
  --region $TARGET_REGION)

echo "æ‡‰ç”¨ç¨‹å¼ç«¯é»: http://$ALB_DNS"
echo "æ¸¬è©¦æ‡‰ç”¨ç¨‹å¼å¥åº·æª¢æŸ¥..."
curl -f http://$ALB_DNS/health || echo "å¥åº·æª¢æŸ¥å¤±æ•—ï¼Œè«‹æª¢æŸ¥æ‡‰ç”¨ç¨‹å¼ç‹€æ…‹"

echo "âœ… EC2 éƒ¨ç½²é©—è­‰å®Œæˆï¼"
```

```bash
#!/bin/bash
# create_and_copy_ami.sh
source config.sh

INSTANCE_ID="i-1234567890abcdef0"  # æ›¿æ›ç‚ºå¯¦éš›çš„åŸ·è¡Œå€‹é«” ID
AMI_NAME="my-app-ami-$(date +%Y%m%d-%H%M%S)"

echo "ğŸ–¼ï¸ å»ºç«‹å’Œè¤‡è£½ AMI..."

# å¾ä¾†æºå€åŸŸçš„ EC2 åŸ·è¡Œå€‹é«”å»ºç«‹ AMI
aws ec2 create-image \
  --instance-id $INSTANCE_ID \
  --name "$AMI_NAME" \
  --description "Application AMI for TPE migration" \
  --no-reboot \
  --region $SOURCE_REGION

# ç²å–å»ºç«‹çš„ AMI ID
SOURCE_AMI_ID=$(aws ec2 describe-images --owners self --filters "Name=name,Values=$AMI_NAME" --query 'Images[0].ImageId' --output text --region $SOURCE_REGION)

# ç­‰å¾… AMI å»ºç«‹å®Œæˆ
echo "â³ ç­‰å¾… AMI å»ºç«‹å®Œæˆ..."
aws ec2 wait image-available \
  --image-ids $SOURCE_AMI_ID \
  --region $SOURCE_REGION

# è¤‡è£½ AMI åˆ°ç›®æ¨™å€åŸŸ
TARGET_AMI_ID=$(aws ec2 copy-image \
  --source-image-id $SOURCE_AMI_ID \
  --source-region $SOURCE_REGION \
  --name "$AMI_NAME-tpe" \
  --description "Application AMI copied to TPE region" \
  --query 'ImageId' \
  --output text \
  --region $TARGET_REGION)

echo "ä¾†æº AMI ID: $SOURCE_AMI_ID"
echo "ç›®æ¨™ AMI ID: $TARGET_AMI_ID"

# å„²å­˜ AMI ID ä¾›å¾ŒçºŒä½¿ç”¨
echo $TARGET_AMI_ID > target_ami_id.txt

# ç­‰å¾… AMI è¤‡è£½å®Œæˆ
echo "â³ ç­‰å¾… AMI è¤‡è£½å®Œæˆ..."
aws ec2 wait image-available \
  --image-ids $TARGET_AMI_ID \
  --region $TARGET_REGION

echo "âœ… AMI å»ºç«‹å’Œè¤‡è£½å®Œæˆï¼"
```

### 2. å»ºç«‹å•Ÿå‹•ç¯„æœ¬å’Œ Load Balancer

```bash
#!/bin/bash
# setup_ec2_infrastructure.sh
source config.sh

TARGET_AMI_ID=$(cat target_ami_id.txt)

echo "ğŸ—ï¸ å»ºç«‹ EC2 åŸºç¤è¨­æ–½..."

# ç²å–å¿…è¦çš„è³‡æº ID
TARGET_VPC_ID=$(aws ec2 describe-vpcs --filters "Name=tag:Name,Values=your-vpc" --query 'Vpcs[0].VpcId' --output text --region $TARGET_REGION)
PRIVATE_SUBNET_IDS=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$TARGET_VPC_ID" "Name=tag:Type,Values=Private" --query 'Subnets[].SubnetId' --output text --region $TARGET_REGION)
PUBLIC_SUBNET_IDS=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$TARGET_VPC_ID" "Name=tag:Type,Values=Public" --query 'Subnets[].SubnetId' --output text --region $TARGET_REGION)
SECURITY_GROUP_ID=$(aws ec2 describe-security-groups --filters "Name=vpc-id,Values=$TARGET_VPC_ID" "Name=group-name,Values=ec2-app-sg" --query 'SecurityGroups[0].GroupId' --output text --region $TARGET_REGION)
KEY_PAIR_NAME="my-key-pair"  # æ›¿æ›ç‚ºå¯¦éš›çš„é‡‘é‘°å°åç¨±

# æº–å‚™ User Data è…³æœ¬
cat > user-data.sh << EOF
#!/bin/bash
yum update -y
# å®‰è£æ‡‰ç”¨ç¨‹å¼ç›¸ä¾æ€§
yum install -y docker
systemctl start docker
systemctl enable docker

# æ›´æ–°æ‡‰ç”¨ç¨‹å¼è¨­å®šæŒ‡å‘æ–°çš„è³‡æ–™åº«
sed -i 's/${DB_INSTANCE_ID}/${DB_INSTANCE_ID}-tpe/g' /etc/myapp/config.properties
systemctl restart myapp
EOF

# å»ºç«‹å•Ÿå‹•ç¯„æœ¬
aws ec2 create-launch-template \
  --launch-template-name tpe-app-launch-template \
  --launch-template-data "{
    \"ImageId\": \"$TARGET_AMI_ID\",
    \"InstanceType\": \"t3.medium\",
    \"KeyName\": \"$KEY_PAIR_NAME\",
    \"SecurityGroupIds\": [\"$SECURITY_GROUP_ID\"],
    \"UserData\": \"$(base64 -w 0 user-data.sh)\",
    \"IamInstanceProfile\": {
      \"Name\": \"EC2-App-InstanceProfile\"
    },
    \"TagSpecifications\": [{
      \"ResourceType\": \"instance\",
      \"Tags\": [
        {\"Key\": \"Name\", \"Value\": \"tpe-app-instance\"},
        {\"Key\": \"Environment\", \"Value\": \"production\"},
        {\"Key\": \"Project\", \"Value\": \"tpe-migration\"}
      ]
    }]
  }" \
  --region $TARGET_REGION

# å»ºç«‹ Application Load Balancer
ALB_ARN=$(aws elbv2 create-load-balancer \
  --name tpe-ec2-alb \
  --subnets $PUBLIC_SUBNET_IDS \
  --security-groups $SECURITY_GROUP_ID \
  --scheme internet-facing \
  --type application \
  --ip-address-type ipv4 \
  --query 'LoadBalancers[0].LoadBalancerArn' \
  --output text \
  --region $TARGET_REGION)

# å»ºç«‹ç›®æ¨™ç¾¤çµ„
TARGET_GROUP_ARN=$(aws elbv2 create-target-group \
  --name tpe-ec2-targets \
  --protocol HTTP \
  --port 80 \
  --vpc-id $TARGET_VPC_ID \
  --target-type instance \
  --health-check-enabled \
  --health-check-path /health \
  --health-check-interval-seconds 30 \
  --health-check-timeout-seconds 5 \
  --healthy-threshold-count 2 \
  --unhealthy-threshold-count 3 \
  --query 'TargetGroups[0].TargetGroupArn' \
  --output text \
  --region $TARGET_REGION)

# å»ºç«‹ç›£è½å™¨
aws elbv2 create-listener \
  --load-balancer-arn $ALB_ARN \
  --protocol HTTP \
  --port 80 \
  --default-actions Type=forward,TargetGroupArn=$TARGET_GROUP_ARN \
  --region $TARGET_REGION

# å„²å­˜ ARN ä¾›å¾ŒçºŒä½¿ç”¨
echo $ALB_ARN > alb_arn.txt
echo $TARGET_GROUP_ARN > target_group_arn.txt

echo "ALB ARN: $ALB_ARN"
echo "Target Group ARN: $TARGET_GROUP_ARN"
echo "âœ… EC2 åŸºç¤è¨­æ–½å»ºç«‹å®Œæˆï¼"
```

### 3. å»ºç«‹ Auto Scaling ç¾¤çµ„

```bash
#!/bin/bash
# create_autoscaling_group.sh
source config.sh

TARGET_GROUP_ARN=$(cat target_group_arn.txt)

echo "ğŸ“ˆ å»ºç«‹ Auto Scaling ç¾¤çµ„..."

# ç²å–ç§æœ‰å­ç¶²è·¯ IDï¼ˆç”¨æ–¼ EC2 åŸ·è¡Œå€‹é«”ï¼‰
TARGET_VPC_ID=$(aws ec2 describe-vpcs --filters "Name=tag:Name,Values=your-vpc" --query 'Vpcs[0].VpcId' --output text --region $TARGET_REGION)
PRIVATE_SUBNET_IDS=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$TARGET_VPC_ID" "Name=tag:Type,Values=Private" --query 'Subnets[].SubnetId' --output text --region $TARGET_REGION)

# å»ºç«‹ Auto Scaling ç¾¤çµ„
aws autoscaling create-auto-scaling-group \
  --auto-scaling-group-name tpe-app-asg \
  --launch-template "{
    \"LaunchTemplateName\": \"tpe-app-launch-template\",
    \"Version\": \"\$Latest\"
  }" \
  --min-size 2 \
  --max-size 10 \
  --desired-capacity 3 \
  --vpc-zone-identifier "$(echo $PRIVATE_SUBNET_IDS | tr ' ' ',')" \
  --target-group-arns $TARGET_GROUP_ARN \
  --health-check-type ELB \
  --health-check-grace-period 300 \
  --default-cooldown 300 \
  --tags "Key=Name,Value=tpe-app-asg-instance,PropagateAtLaunch=true,ResourceId=tpe-app-asg,ResourceType=auto-scaling-group" \
  --region $TARGET_REGION

# å»ºç«‹æ“´å±•æ”¿ç­–
aws autoscaling put-scaling-policy \
  --auto-scaling-group-name tpe-app-asg \
  --policy-name scale-up-policy \
  --policy-type TargetTrackingScaling \
  --target-tracking-configuration '{
    "TargetValue": 70.0,
    "PredefinedMetricSpecification": {
      "PredefinedMetricType": "ASGAverageCPUUtilization"
    }
  }' \
  --region $TARGET_REGION

# ç­‰å¾…åŸ·è¡Œå€‹é«”å•Ÿå‹•
echo "â³ ç­‰å¾… Auto Scaling ç¾¤çµ„åŸ·è¡Œå€‹é«”å•Ÿå‹•..."
sleep 120

# æª¢æŸ¥ Auto Scaling ç¾¤çµ„ç‹€æ…‹
aws autoscaling describe-auto-scaling-groups \
  --auto-scaling-group-names tpe-app-asg \
  --query 'AutoScalingGroups[0].{DesiredCapacity:DesiredCapacity,MinSize:MinSize,MaxSize:MaxSize,Instances:length(Instances)}' \
  --region $TARGET_REGION

echo "âœ… Auto Scaling ç¾¤çµ„å»ºç«‹å®Œæˆï¼"
```

## RDS è³‡æ–™åº«é·ç§»ï¼ˆæ‰€æœ‰æ¡ˆä¾‹é€šç”¨ï¼‰

### RDS å¿«ç…§ + DMS å·®ç•°åŒæ­¥

```bash
#!/bin/bash
# migrate_rds_with_dms.sh
source config.sh

SNAPSHOT_ID="migration-snapshot-$(date +%Y%m%d-%H%M%S)"

echo "ğŸš€ é–‹å§‹ RDS è³‡æ–™åº«é·ç§»ï¼ˆå¿«ç…§ + DMS ç­–ç•¥ï¼‰..."

# 1. å»ºç«‹ RDS å¿«ç…§
echo "ğŸ“¸ å»ºç«‹ RDS å¿«ç…§: $SNAPSHOT_ID"
aws rds create-db-snapshot \
  --db-instance-identifier $DB_INSTANCE_ID \
  --db-snapshot-identifier $SNAPSHOT_ID \
  --region $SOURCE_REGION

# 2. ç­‰å¾…å¿«ç…§å®Œæˆ
echo "â³ ç­‰å¾…å¿«ç…§å»ºç«‹å®Œæˆ..."
aws rds wait db-snapshot-completed \
  --db-snapshot-identifier $SNAPSHOT_ID \
  --region $SOURCE_REGION

# 3. è¤‡è£½å¿«ç…§åˆ°ç›®æ¨™å€åŸŸ
echo "ğŸ“‹ è¤‡è£½å¿«ç…§åˆ°ç›®æ¨™å€åŸŸ..."
aws rds copy-db-snapshot \
  --source-db-snapshot-identifier arn:aws:rds:$SOURCE_REGION:$AWS_ACCOUNT_ID:snapshot:$SNAPSHOT_ID \
  --target-db-snapshot-identifier $SNAPSHOT_ID \
  --region $TARGET_REGION

# 4. ç­‰å¾…å¿«ç…§è¤‡è£½å®Œæˆ
echo "â³ ç­‰å¾…å¿«ç…§è¤‡è£½å®Œæˆ..."
aws rds wait db-snapshot-completed \
  --db-snapshot-identifier $SNAPSHOT_ID \
  --region $TARGET_REGION

# 5. å¾å¿«ç…§é‚„åŸè³‡æ–™åº«
echo "ğŸ”„ å¾å¿«ç…§é‚„åŸè³‡æ–™åº«..."
aws rds restore-db-instance-from-db-snapshot \
  --db-instance-identifier ${DB_INSTANCE_ID}-tpe \
  --db-snapshot-identifier $SNAPSHOT_ID \
  --region $TARGET_REGION

# 6. ç­‰å¾…è³‡æ–™åº«å¯ç”¨
echo "â³ ç­‰å¾…è³‡æ–™åº«é‚„åŸå®Œæˆ..."
aws rds wait db-instance-available \
  --db-instance-identifier ${DB_INSTANCE_ID}-tpe \
  --region $TARGET_REGION

# 7. è¨­å®š DMS é€²è¡Œå·®ç•°åŒæ­¥
echo "ğŸ”§ è¨­å®š DMS å·®ç•°åŒæ­¥..."

# ç²å–ç›®æ¨™ VPC è³‡è¨Š
TARGET_VPC_ID=$(aws ec2 describe-vpcs --filters "Name=tag:Name,Values=your-vpc" --query 'Vpcs[0].VpcId' --output text --region $TARGET_REGION)
TARGET_SUBNET_IDS=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$TARGET_VPC_ID" --query 'Subnets[].SubnetId' --output text --region $TARGET_REGION)

# å»ºç«‹ DMS å­ç¶²è·¯ç¾¤çµ„
aws dms create-replication-subnet-group \
  --replication-subnet-group-identifier dms-subnet-group \
  --replication-subnet-group-description "DMS subnet group for migration" \
  --subnet-ids $TARGET_SUBNET_IDS \
  --region $TARGET_REGION

# å»ºç«‹ DMS è¤‡è£½åŸ·è¡Œå€‹é«”
aws dms create-replication-instance \
  --replication-instance-identifier dms-migration-instance \
  --replication-instance-class dms.t3.micro \
  --replication-subnet-group-identifier dms-subnet-group \
  --region $TARGET_REGION

# ç­‰å¾… DMS åŸ·è¡Œå€‹é«”å¯ç”¨
echo "â³ ç­‰å¾… DMS åŸ·è¡Œå€‹é«”æº–å‚™å®Œæˆ..."
aws dms wait replication-instance-available \
  --filters "Name=replication-instance-id,Values=dms-migration-instance" \
  --region $TARGET_REGION

echo "âœ… RDS é·ç§»å®Œæˆï¼DMS å·²æº–å‚™å¥½é€²è¡Œå·®ç•°åŒæ­¥ã€‚"
```

### RDS é·ç§»é©—è­‰

```bash
#!/bin/bash
# verify_rds_migration.sh
source config.sh

SOURCE_DB=$DB_INSTANCE_ID
TARGET_DB="${DB_INSTANCE_ID}-tpe"

echo "ğŸ” é©—è­‰ RDS é·ç§»ç‹€æ…‹..."

# æª¢æŸ¥ä¾†æºè³‡æ–™åº«ç‹€æ…‹
echo "ä¾†æºè³‡æ–™åº«ç‹€æ…‹ï¼š"
aws rds describe-db-instances \
  --db-instance-identifier $SOURCE_DB \
  --region $SOURCE_REGION \
  --query 'DBInstances[0].{Status:DBInstanceStatus,Engine:Engine,Version:EngineVersion,Size:DBInstanceClass}' \
  --output table

# æª¢æŸ¥ç›®æ¨™è³‡æ–™åº«ç‹€æ…‹
echo "ç›®æ¨™è³‡æ–™åº«ç‹€æ…‹ï¼š"
aws rds describe-db-instances \
  --db-instance-identifier $TARGET_DB \
  --region $TARGET_REGION \
  --query 'DBInstances[0].{Status:DBInstanceStatus,Engine:Engine,Version:EngineVersion,Size:DBInstanceClass}' \
  --output table

# æª¢æŸ¥ DMS è¤‡è£½åŸ·è¡Œå€‹é«”ç‹€æ…‹
echo "DMS è¤‡è£½åŸ·è¡Œå€‹é«”ç‹€æ…‹ï¼š"
aws dms describe-replication-instances \
  --filters "Name=replication-instance-id,Values=dms-migration-instance" \
  --region $TARGET_REGION \
  --query 'ReplicationInstances[0].{Status:ReplicationInstanceStatus,Class:ReplicationInstanceClass}' \
  --output table
```

## å®Œæ•´è‡ªå‹•åŒ–é·ç§»è…³æœ¬

### ä¸»æ§åˆ¶è…³æœ¬

```bash
#!/bin/bash
# complete_migration.sh
MIGRATION_TYPE="$1"  # eks, ecs, ec2, or rds

# è¼‰å…¥è¨­å®š
source config.sh

# å‰ç½®ä½œæ¥­ï¼šè¨­å®š ECR è¤‡è£½
echo "ğŸ”„ è¨­å®š ECR è·¨å€åŸŸè¤‡è£½..."
./setup_ecr_replication.sh

case $MIGRATION_TYPE in
    "eks")
        echo "ğŸš€ é–‹å§‹ EKS å®Œæ•´é·ç§»..."
        # ä¸¦è¡ŒåŸ·è¡Œ RDS é·ç§»
        ./migrate_rds_with_dms.sh &
        RDS_PID=$!
        
        # åŸ·è¡Œ EKS é·ç§»
        ./export_eks_config.sh
        ./modify_eks_config.sh
        ./deploy_eks_cluster.sh
        
        # ç­‰å¾… RDS é·ç§»å®Œæˆ
        wait $RDS_PID
        
        # éƒ¨ç½² Kubernetes æ‡‰ç”¨ç¨‹å¼
        ./migrate_k8s_apps.sh
        echo "âœ… EKS å®Œæ•´é·ç§»å®Œæˆï¼"
        ;;
    "ecs")
        echo "ğŸš€ é–‹å§‹ ECS å®Œæ•´é·ç§»..."
        # ä¸¦è¡ŒåŸ·è¡Œ RDS é·ç§»
        ./migrate_rds_with_dms.sh &
        RDS_PID=$!
        
        # åŸ·è¡Œ ECS é·ç§»
        ./export_ecs_config.sh
        ./deploy_ecs_cluster.sh
        
        # ç­‰å¾… RDS é·ç§»å®Œæˆ
        wait $RDS_PID
        echo "âœ… ECS å®Œæ•´é·ç§»å®Œæˆï¼"
        ;;
    "ec2")
        echo "ğŸš€ é–‹å§‹ EC2 å®Œæ•´é·ç§»..."
        # ä¸¦è¡ŒåŸ·è¡Œ RDS é·ç§»
        ./migrate_rds_with_dms.sh &
        RDS_PID=$!
        
        # åŸ·è¡Œ EC2 é·ç§»
        ./create_and_copy_ami.sh
        ./setup_ec2_infrastructure.sh
        ./create_autoscaling_group.sh
        
        # ç­‰å¾… RDS é·ç§»å®Œæˆ
        wait $RDS_PID
        
        # é©—è­‰éƒ¨ç½²
        ./verify_ec2_deployment.sh
        echo "âœ… EC2 å®Œæ•´é·ç§»å®Œæˆï¼"
        ;;
    "rds")
        echo "ğŸš€ é–‹å§‹ RDS é·ç§»..."
        ./migrate_rds_with_dms.sh
        echo "âœ… RDS é·ç§»å®Œæˆï¼"
        ;;
    "all")
        echo "ğŸš€ é–‹å§‹å®Œæ•´é·ç§»..."
        ./setup_ecr_replication.sh
        ./migrate_rds_with_dms.sh &
        ./$0 $2  # eks, ecs, or ec2
        wait
        echo "âœ… å®Œæ•´é·ç§»å®Œæˆï¼"
        ;;
    *)
        echo "ä½¿ç”¨æ–¹å¼: $0 [eks|ecs|ec2|rds|all] [eks|ecs|ec2]"
        echo "ç¯„ä¾‹: $0 all eks  # åŒæ™‚é·ç§» ECR + RDS + EKS"
        echo "ç¯„ä¾‹: $0 all ecs  # åŒæ™‚é·ç§» ECR + RDS + ECS"
        echo "ç¯„ä¾‹: $0 all ec2  # åŒæ™‚é·ç§» ECR + RDS + EC2"
        exit 1
        ;;
esac
```

## é©—è­‰æª¢æŸ¥æ¸…å–®

### ç¶œåˆé©—è­‰è…³æœ¬

```bash
#!/bin/bash
# verify_migration.sh
source config.sh

SERVICE_TYPE="$1"  # eks, ecs, or ec2

echo "ğŸ” é–‹å§‹é©—è­‰é·ç§»çµæœ..."

# 1. é©—è­‰ ECR è¤‡è£½
echo "1ï¸âƒ£ é©—è­‰ ECR æ˜ åƒè¤‡è£½..."
./verify_ecr_replication.sh

# 2. é©—è­‰ RDS é·ç§»
echo "2ï¸âƒ£ é©—è­‰ RDS è³‡æ–™åº«é·ç§»..."
./verify_rds_migration.sh

# 3. é©—è­‰è¨ˆç®—æœå‹™
case $SERVICE_TYPE in
    "eks")
        echo "3ï¸âƒ£ é©—è­‰ EKS é·ç§»..."
        aws eks describe-cluster --name $CLUSTER_NAME --region $TARGET_REGION --query 'cluster.status'
        kubectl get nodes
        kubectl get pods --all-namespaces
        kubectl get services --all-namespaces
        ;;
    "ecs")
        echo "3ï¸âƒ£ é©—è­‰ ECS é·ç§»..."
        aws ecs describe-clusters --clusters $CLUSTER_NAME --region $TARGET_REGION --query 'clusters[0].status'
        aws ecs list-services --cluster $CLUSTER_NAME --region $TARGET_REGION
        
        # æª¢æŸ¥æœå‹™å¥åº·ç‹€æ…‹
        for service in $(aws ecs list-services --cluster $CLUSTER_NAME --region $TARGET_REGION --query 'serviceArns' --output text); do
            service_name=$(basename $service)
            echo "æª¢æŸ¥æœå‹™: $service_name"
            aws ecs describe-services --cluster $CLUSTER_NAME --services $service_name --region $TARGET_REGION \
              --query 'services[0].{Status:status,Running:runningCount,Desired:desiredCount}'
        done
        ;;
    "ec2")
        echo "3ï¸âƒ£ é©—è­‰ EC2 é·ç§»..."
        ./verify_ec2_deployment.sh
        ;;
esac

echo "âœ… é©—è­‰å®Œæˆï¼"
```

## DNS æµé‡åˆ‡æ›

### Route 53 æµé‡åˆ‡æ›è…³æœ¬

```bash
#!/bin/bash
# switch_dns_traffic.sh
source config.sh

SERVICE_TYPE="$1"  # eks, ecs, or ec2
HOSTED_ZONE_ID="Z123456789"  # æ›¿æ›ç‚ºå¯¦éš›çš„ Hosted Zone ID
DOMAIN_NAME="app.example.com"

echo "ğŸ”„ é–‹å§‹ DNS æµé‡åˆ‡æ›..."

# æ ¹æ“šæœå‹™é¡å‹ç²å–ç›®æ¨™ç«¯é»
case $SERVICE_TYPE in
    "eks")
        # ç²å– EKS Ingress æˆ– LoadBalancer ç«¯é»
        TARGET_ENDPOINT=$(kubectl --context=target-cluster get ingress -o jsonpath='{.items[0].status.loadBalancer.ingress[0].hostname}')
        ;;
    "ecs")
        # ç²å– ECS ALB ç«¯é»
        TARGET_ENDPOINT=$(aws elbv2 describe-load-balancers --names tpe-ecs-alb --query 'LoadBalancers[0].DNSName' --output text --region $TARGET_REGION)
        ;;
    "ec2")
        # ç²å– EC2 ALB ç«¯é»
        ALB_ARN=$(cat alb_arn.txt)
        TARGET_ENDPOINT=$(aws elbv2 describe-load-balancers --load-balancer-arns $ALB_ARN --query 'LoadBalancers[0].DNSName' --output text --region $TARGET_REGION)
        ;;
esac

echo "ç›®æ¨™ç«¯é»: $TARGET_ENDPOINT"

# æ¼¸é€²å¼æµé‡åˆ‡æ›ï¼ˆå¾ 10% é–‹å§‹ï¼‰
for weight in 10 25 50 75 100; do
    echo "åˆ‡æ› $weight% æµé‡åˆ° TPE Region..."
    
    aws route53 change-resource-record-sets \
      --hosted-zone-id $HOSTED_ZONE_ID \
      --change-batch "{
        \"Changes\": [{
          \"Action\": \"UPSERT\",
          \"ResourceRecordSet\": {
            \"Name\": \"$DOMAIN_NAME\",
            \"Type\": \"CNAME\",
            \"SetIdentifier\": \"TPE-$SERVICE_TYPE\",
            \"Weight\": $weight,
            \"TTL\": 60,
            \"ResourceRecords\": [{\"Value\": \"$TARGET_ENDPOINT\"}]
          }
        }]
      }"
    
    echo "ç­‰å¾… 2 åˆ†é˜è§€å¯Ÿæµé‡..."
    sleep 120
    
    # æª¢æŸ¥å¥åº·ç‹€æ…‹
    echo "æª¢æŸ¥æ‡‰ç”¨ç¨‹å¼å¥åº·ç‹€æ…‹..."
    curl -f http://$TARGET_ENDPOINT/health || echo "å¥åº·æª¢æŸ¥å¤±æ•—ï¼"
    
    read -p "ç¹¼çºŒä¸‹ä¸€éšæ®µåˆ‡æ›ï¼Ÿ(y/n): " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        echo "æµé‡åˆ‡æ›æš«åœåœ¨ $weight%"
        exit 1
    fi
done

echo "âœ… DNS æµé‡åˆ‡æ›å®Œæˆï¼"
```

## å›æ»¾è…³æœ¬

### ç·Šæ€¥å›æ»¾è…³æœ¬

```bash
#!/bin/bash
# emergency_rollback.sh
source config.sh

SERVICE_TYPE="$1"  # eks, ecs, or ec2
HOSTED_ZONE_ID="Z123456789"
DOMAIN_NAME="app.example.com"

echo "ğŸš¨ åŸ·è¡Œç·Šæ€¥å›æ»¾..."

# 1. DNS ç«‹å³åˆ‡æ›å›åŸå€åŸŸ
echo "1ï¸âƒ£ DNS ç«‹å³åˆ‡æ›å›åŸå€åŸŸ..."
aws route53 change-resource-record-sets \
  --hosted-zone-id $HOSTED_ZONE_ID \
  --change-batch "{
    \"Changes\": [{
      \"Action\": \"DELETE\",
      \"ResourceRecordSet\": {
        \"Name\": \"$DOMAIN_NAME\",
        \"Type\": \"CNAME\",
        \"SetIdentifier\": \"TPE-$SERVICE_TYPE\",
        \"Weight\": 100,
        \"TTL\": 60,
        \"ResourceRecords\": [{\"Value\": \"original-endpoint.com\"}]
      }
    }]
  }"

# 2. æœå‹™ç‰¹å®šå›æ»¾
case $SERVICE_TYPE in
    "eks")
        echo "2ï¸âƒ£ EKS å›æ»¾..."
        kubectl config use-context source-cluster
        kubectl apply -f original-deployment.yaml
        ;;
    "ecs")
        echo "2ï¸âƒ£ ECS å›æ»¾..."
        aws ecs update-service \
          --cluster original-ecs-cluster \
          --service my-app-service \
          --desired-count 3 \
          --region $SOURCE_REGION
        ;;
    "ec2")
        echo "2ï¸âƒ£ EC2 å›æ»¾..."
        aws autoscaling update-auto-scaling-group \
          --auto-scaling-group-name original-app-asg \
          --desired-capacity 3 \
          --region $SOURCE_REGION
        ;;
esac

echo "âœ… ç·Šæ€¥å›æ»¾å®Œæˆï¼"
```

## ä½¿ç”¨èªªæ˜

### å¿«é€Ÿé–‹å§‹

```bash
# 1. è¨­å®šç’°å¢ƒè®Šæ•¸
cp config.sh.example config.sh
# ç·¨è¼¯ config.sh å¡«å…¥å¯¦éš›å€¼

# 2. åŸ·è¡Œå®Œæ•´é·ç§»
./complete_migration.sh all eks    # EKS + ECR + RDS
./complete_migration.sh all ecs    # ECS + ECR + RDS  
./complete_migration.sh all ec2    # EC2 + ECR + RDS

# 3. é©—è­‰é·ç§»çµæœ
./verify_migration.sh eks
./verify_migration.sh ecs
./verify_migration.sh ec2

# 4. åŸ·è¡Œæµé‡åˆ‡æ›
./switch_dns_traffic.sh eks
./switch_dns_traffic.sh ecs
./switch_dns_traffic.sh ec2

# 5. å¦‚éœ€å›æ»¾
./emergency_rollback.sh eks
```

### è…³æœ¬æ¬Šé™è¨­å®š

```bash
# è¨­å®šæ‰€æœ‰è…³æœ¬ç‚ºå¯åŸ·è¡Œ
chmod +x *.sh

# æˆ–å€‹åˆ¥è¨­å®š
chmod +x complete_migration.sh
chmod +x verify_migration.sh
chmod +x switch_dns_traffic.sh
```

é€™å€‹éƒ¨ç½²æŒ‡å—æä¾›äº†å®Œæ•´çš„å¯åŸ·è¡Œå‘½ä»¤ï¼Œæ¶µè“‹ EKSã€ECSã€EC2 ä¸‰ç¨®è¨ˆç®—æœå‹™çš„é·ç§»ï¼Œä»¥åŠ ECRã€RDSã€DMS çš„æ•´åˆï¼Œè®“æ‚¨å¯ä»¥ç›´æ¥åŸ·è¡Œè·¨å€åŸŸé·ç§»ï¼
