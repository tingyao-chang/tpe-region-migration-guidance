# EKS è·¨å€åŸŸé·ç§»éƒ¨ç½²æŒ‡å—

## æ¦‚è¿°

æœ¬æŒ‡å—æä¾› EKS å¢é›†å¾ Tokyo Region â†’ Taipei Region é·ç§»çš„å…·é«”åŸ·è¡Œå‘½ä»¤å’Œè…³æœ¬ã€‚

## å‰ç½®æº–å‚™

### ç’°å¢ƒè®Šæ•¸è¨­å®š

```bash
# 1. è¤‡è£½è¨­å®šæª”ç¯„æœ¬
cp config.sh.example config.sh

# 2. ç·¨è¼¯ config.sh å¡«å…¥å¯¦éš›å€¼
# å¿…è¦è¨­å®šï¼š
# - CLUSTER_NAME: EKS å¢é›†åç¨±
# - VPC_NAME: ç›®æ¨™å€åŸŸçš„ VPC åç¨±
# é¸ç”¨è¨­å®šï¼š
# - DB_INSTANCE_ID: å¦‚æœæœ‰ RDS è³‡æ–™åº«éœ€è¦é·ç§»
# - DOMAIN_NAME, HOSTED_ZONE_ID: å¦‚æœéœ€è¦ DNS æµé‡åˆ‡æ›

# 3. é©—è­‰è¨­å®š
./config.sh
```

### VPC åŸºç¤è¨­æ–½æº–å‚™

```bash
# è¼‰å…¥å…±ç”¨å‡½æ•¸
source common_functions.sh
load_config
validate_basic_config

# æ–¹æ¡ˆ Aï¼šè¤‡è£½ä¾†æºå€åŸŸ VPC è¨­å®šï¼ˆæ¨è–¦ï¼‰
./replicate_vpc_from_source.sh

# æ–¹æ¡ˆ Bï¼šå»ºç«‹å…¨æ–° VPC
./create_new_vpc.sh

# é©—è­‰ VPC è³‡æº
get_vpc_resources
```

## EKS é·ç§»æ­¥é©Ÿ

### 1. åŒ¯å‡º EKS å¢é›†è¨­å®š

```bash
#!/bin/bash
# export_eks_config.sh
source common_functions.sh
load_config
validate_basic_config

echo "ğŸ“¤ åŒ¯å‡º EKS å¢é›†è¨­å®š..."

# é©—è­‰ EKS ç‰¹å®šè¨­å®š
if [[ -z "$CLUSTER_NAME" ]]; then
    echo "âŒ éŒ¯èª¤ï¼šCLUSTER_NAME æœªè¨­å®š"
    exit 1
fi

# 1. åŒ¯å‡ºå¢é›†åŸºæœ¬è¨­å®š
aws eks describe-cluster \
  --name $CLUSTER_NAME \
  --region $SOURCE_REGION \
  --query 'cluster.{name:name,version:version,roleArn:roleArn,resourcesVpcConfig:resourcesVpcConfig,logging:logging,encryptionConfig:encryptionConfig,tags:tags}' \
  > eks-cluster-config.json

echo "å¢é›†è¨­å®šå·²åŒ¯å‡ºåˆ° eks-cluster-config.json"

# 2. åŒ¯å‡ºç¯€é»ç¾¤çµ„è¨­å®š
aws eks list-nodegroups \
  --cluster-name $CLUSTER_NAME \
  --region $SOURCE_REGION \
  --query 'nodegroups' \
  --output text | while read nodegroup; do
    echo "åŒ¯å‡ºç¯€é»ç¾¤çµ„: $nodegroup"
    aws eks describe-nodegroup \
      --cluster-name $CLUSTER_NAME \
      --nodegroup-name $nodegroup \
      --region $SOURCE_REGION \
      --query 'nodegroup.{nodegroupName:nodegroupName,scalingConfig:scalingConfig,instanceTypes:instanceTypes,amiType:amiType,capacityType:capacityType,diskSize:diskSize,remoteAccess:remoteAccess,labels:labels,taints:taints,tags:tags}' \
      > "nodegroup-${nodegroup}-config.json"
done

# 3. åŒ¯å‡º Fargate è¨­å®šæª”ï¼ˆå¦‚æœæœ‰ï¼‰
aws eks list-fargate-profiles \
  --cluster-name $CLUSTER_NAME \
  --region $SOURCE_REGION \
  --query 'fargateProfileNames' \
  --output text | while read profile; do
    if [ "$profile" != "None" ]; then
        echo "åŒ¯å‡º Fargate è¨­å®šæª”: $profile"
        aws eks describe-fargate-profile \
          --cluster-name $CLUSTER_NAME \
          --fargate-profile-name $profile \
          --region $SOURCE_REGION \
          --query 'fargateProfile.{fargateProfileName:fargateProfileName,podExecutionRoleArn:podExecutionRoleArn,subnets:subnets,selectors:selectors,tags:tags}' \
          > "fargate-${profile}-config.json"
    fi
done

# 4. åŒ¯å‡ºé™„åŠ å…ƒä»¶è¨­å®š
aws eks list-addons \
  --cluster-name $CLUSTER_NAME \
  --region $SOURCE_REGION \
  --query 'addons' \
  --output text | while read addon; do
    echo "åŒ¯å‡ºé™„åŠ å…ƒä»¶: $addon"
    aws eks describe-addon \
      --cluster-name $CLUSTER_NAME \
      --addon-name $addon \
      --region $SOURCE_REGION \
      --query 'addon.{addonName:addonName,addonVersion:addonVersion,configurationValues:configurationValues,tags:tags}' \
      > "addon-${addon}-config.json"
done

echo "âœ… EKS å¢é›†è¨­å®šåŒ¯å‡ºå®Œæˆï¼"
```

### 2. ä¿®æ”¹å€åŸŸç‰¹å®šè¨­å®š

```bash
#!/bin/bash
# modify_eks_config.sh
source common_functions.sh
load_config
validate_basic_config

echo "ğŸ”§ ä¿®æ”¹å€åŸŸç‰¹å®šè¨­å®š..."

# ç²å– VPC è³‡æº
get_vpc_resources

# å»ºç«‹ EKS å®‰å…¨ç¾¤çµ„
EKS_SECURITY_GROUP_ID=$(create_or_get_security_group "EKS-Cluster" "eks-cluster-sg" "Security group for EKS cluster migration")
add_security_group_rules $EKS_SECURITY_GROUP_ID "app"

# è¨­å®šè®Šæ•¸ä¾›å¾ŒçºŒä½¿ç”¨
TARGET_SUBNET_IDS="$PRIVATE_SUBNET_IDS $PUBLIC_SUBNET_IDS"
TARGET_SECURITY_GROUP_ID="$EKS_SECURITY_GROUP_ID"

# æ›´æ–°å¢é›†è¨­å®šæª”
jq --arg subnets "$(echo $TARGET_SUBNET_IDS | tr ' ' ',')" \
   --arg sg "$TARGET_SECURITY_GROUP_ID" \
   '.resourcesVpcConfig.subnetIds = ($subnets | split(",")) | 
    .resourcesVpcConfig.securityGroupIds = [$sg]' \
   eks-cluster-config.json > eks-cluster-config-modified.json

# æ›´æ–°ç¯€é»ç¾¤çµ„è¨­å®šæª”
for nodegroup_file in nodegroup-*-config.json; do
    if [ -f "$nodegroup_file" ]; then
        echo "æ›´æ–°ç¯€é»ç¾¤çµ„è¨­å®š: $nodegroup_file"
        jq --arg subnets "$(echo $PRIVATE_SUBNET_IDS | tr ' ' ',')" \
           '.subnets = ($subnets | split(","))' \
           "$nodegroup_file" > "${nodegroup_file%.json}-modified.json"
    fi
done

# æ›´æ–° Fargate è¨­å®šæª”
for fargate_file in fargate-*-config.json; do
    if [ -f "$fargate_file" ]; then
        echo "æ›´æ–° Fargate è¨­å®š: $fargate_file"
        jq --arg subnets "$(echo $PRIVATE_SUBNET_IDS | tr ' ' ',')" \
           '.subnets = ($subnets | split(","))' \
           "$fargate_file" > "${fargate_file%.json}-modified.json"
    fi
done

echo "âœ… å€åŸŸç‰¹å®šè¨­å®šä¿®æ”¹å®Œæˆï¼"
```

### 3. éƒ¨ç½²åˆ° Taipei Region

```bash
#!/bin/bash
# deploy_eks_cluster.sh
source common_functions.sh
load_config
validate_basic_config

echo "ğŸš€ åœ¨ Taipei Region éƒ¨ç½² EKS å¢é›†..."

# 1. å»ºç«‹ EKS å¢é›†
CLUSTER_CONFIG=$(cat eks-cluster-config-modified.json)

aws eks create-cluster \
  --region $TARGET_REGION \
  --name $(echo $CLUSTER_CONFIG | jq -r '.name') \
  --version $(echo $CLUSTER_CONFIG | jq -r '.version') \
  --role-arn $(echo $CLUSTER_CONFIG | jq -r '.roleArn') \
  --resources-vpc-config "$(echo $CLUSTER_CONFIG | jq -c '.resourcesVpcConfig')" \
  --logging "$(echo $CLUSTER_CONFIG | jq -c '.logging // {}')" \
  --tags "$(echo $CLUSTER_CONFIG | jq -c '.tags // {}')"

# 2. ç­‰å¾…å¢é›†å»ºç«‹å®Œæˆ
echo "â³ ç­‰å¾… EKS å¢é›†å»ºç«‹å®Œæˆ..."
aws eks wait cluster-active \
  --name $CLUSTER_NAME \
  --region $TARGET_REGION

echo "âœ… EKS å¢é›†å»ºç«‹å®Œæˆï¼"

# 3. å»ºç«‹ç¯€é»ç¾¤çµ„
for nodegroup_file in nodegroup-*-modified.json; do
    if [ -f "$nodegroup_file" ]; then
        echo "å»ºç«‹ç¯€é»ç¾¤çµ„: $nodegroup_file"
        
        NODEGROUP_CONFIG=$(cat "$nodegroup_file")
        NODEGROUP_NAME=$(echo $NODEGROUP_CONFIG | jq -r '.nodegroupName')
        
        aws eks create-nodegroup \
          --region $TARGET_REGION \
          --cluster-name $CLUSTER_NAME \
          --nodegroup-name $NODEGROUP_NAME \
          --scaling-config "$(echo $NODEGROUP_CONFIG | jq -c '.scalingConfig')" \
          --instance-types "$(echo $NODEGROUP_CONFIG | jq -c '.instanceTypes')" \
          --ami-type "$(echo $NODEGROUP_CONFIG | jq -r '.amiType')" \
          --capacity-type "$(echo $NODEGROUP_CONFIG | jq -r '.capacityType')" \
          --disk-size "$(echo $NODEGROUP_CONFIG | jq -r '.diskSize')" \
          --subnets "$(echo $NODEGROUP_CONFIG | jq -c '.subnets')" \
          --node-role "$(echo $NODEGROUP_CONFIG | jq -r '.nodeRole')" \
          --labels "$(echo $NODEGROUP_CONFIG | jq -c '.labels // {}')" \
          --tags "$(echo $NODEGROUP_CONFIG | jq -c '.tags // {}')"
        
        # ç­‰å¾…ç¯€é»ç¾¤çµ„å»ºç«‹å®Œæˆ
        echo "â³ ç­‰å¾…ç¯€é»ç¾¤çµ„ $NODEGROUP_NAME å»ºç«‹å®Œæˆ..."
        aws eks wait nodegroup-active \
          --cluster-name $CLUSTER_NAME \
          --nodegroup-name $NODEGROUP_NAME \
          --region $TARGET_REGION
    fi
done

# 4. å»ºç«‹ Fargate è¨­å®šæª”
for fargate_file in fargate-*-modified.json; do
    if [ -f "$fargate_file" ]; then
        echo "å»ºç«‹ Fargate è¨­å®šæª”: $fargate_file"
        
        FARGATE_CONFIG=$(cat "$fargate_file")
        FARGATE_NAME=$(echo $FARGATE_CONFIG | jq -r '.fargateProfileName')
        
        aws eks create-fargate-profile \
          --region $TARGET_REGION \
          --cluster-name $CLUSTER_NAME \
          --fargate-profile-name $FARGATE_NAME \
          --pod-execution-role-arn "$(echo $FARGATE_CONFIG | jq -r '.podExecutionRoleArn')" \
          --subnets "$(echo $FARGATE_CONFIG | jq -c '.subnets')" \
          --selectors "$(echo $FARGATE_CONFIG | jq -c '.selectors')" \
          --tags "$(echo $FARGATE_CONFIG | jq -c '.tags // {}')"
        
        # ç­‰å¾… Fargate è¨­å®šæª”å»ºç«‹å®Œæˆ
        echo "â³ ç­‰å¾… Fargate è¨­å®šæª” $FARGATE_NAME å»ºç«‹å®Œæˆ..."
        aws eks wait fargate-profile-active \
          --cluster-name $CLUSTER_NAME \
          --fargate-profile-name $FARGATE_NAME \
          --region $TARGET_REGION
    fi
done

# 5. å®‰è£é™„åŠ å…ƒä»¶
for addon_file in addon-*-config.json; do
    if [ -f "$addon_file" ]; then
        echo "å®‰è£é™„åŠ å…ƒä»¶: $addon_file"
        
        ADDON_CONFIG=$(cat "$addon_file")
        ADDON_NAME=$(echo $ADDON_CONFIG | jq -r '.addonName')
        
        aws eks create-addon \
          --region $TARGET_REGION \
          --cluster-name $CLUSTER_NAME \
          --addon-name $ADDON_NAME \
          --addon-version "$(echo $ADDON_CONFIG | jq -r '.addonVersion')" \
          --configuration-values "$(echo $ADDON_CONFIG | jq -r '.configurationValues // ""')" \
          --tags "$(echo $ADDON_CONFIG | jq -c '.tags // {}')"
    fi
done

echo "âœ… EKS å¢é›†éƒ¨ç½²å®Œæˆï¼"

# 6. æ›´æ–° kubeconfig
aws eks update-kubeconfig \
  --region $TARGET_REGION \
  --name $CLUSTER_NAME

echo "âœ… kubeconfig å·²æ›´æ–°ï¼Œå¯ä»¥ä½¿ç”¨ kubectl é€£æ¥åˆ°æ–°å¢é›†"
```

### 4. Kubernetes æ‡‰ç”¨ç¨‹å¼é·ç§»

```bash
#!/bin/bash
# migrate_k8s_apps.sh
source config.sh

SOURCE_CLUSTER_CONTEXT="arn:aws:eks:$SOURCE_REGION:$AWS_ACCOUNT_ID:cluster/$CLUSTER_NAME"
TARGET_CLUSTER_CONTEXT="arn:aws:eks:$TARGET_REGION:$AWS_ACCOUNT_ID:cluster/$CLUSTER_NAME"

echo "ğŸ”„ é·ç§» Kubernetes æ‡‰ç”¨ç¨‹å¼..."

# 1. è¨­å®š kubectl context
kubectl config use-context $SOURCE_CLUSTER_CONTEXT

# 2. åŒ¯å‡ºæ‰€æœ‰ Kubernetes è³‡æºï¼ˆæ’é™¤ç³»çµ±å‘½åç©ºé–“ï¼‰
echo "ğŸ“¤ åŒ¯å‡º Kubernetes è³‡æº..."
kubectl get all,configmap,secret,pvc,ingress \
  --all-namespaces \
  --export -o yaml \
  --ignore-not-found=true \
  --field-selector metadata.namespace!=kube-system,metadata.namespace!=kube-public,metadata.namespace!=kube-node-lease \
  > k8s-resources-export.yaml

# 3. è‡ªå‹•ä¿®æ”¹æ˜ åƒè·¯å¾‘å’Œè³‡æ–™åº«è¨­å®š
echo "ğŸ”§ ä¿®æ”¹å®¹å™¨æ˜ åƒè·¯å¾‘å’Œè³‡æ–™åº«è¨­å®š..."
sed "s/ap-northeast-1/ap-east-2/g" k8s-resources-export.yaml | \
sed "s/${DB_INSTANCE_ID}/${DB_INSTANCE_ID}-tpe/g" > k8s-resources-modified.yaml

# 4. éƒ¨ç½²åˆ°ç›®æ¨™å¢é›†
echo "ğŸš€ éƒ¨ç½²åˆ°ç›®æ¨™å¢é›†..."
kubectl config use-context $TARGET_CLUSTER_CONTEXT

# å…ˆå»ºç«‹å‘½åç©ºé–“
kubectl get namespaces -o yaml --export | kubectl apply -f -

# éƒ¨ç½²æ‰€æœ‰è³‡æº
kubectl apply -f k8s-resources-modified.yaml

# 5. é©—è­‰éƒ¨ç½²ç‹€æ…‹
echo "ğŸ” é©—è­‰éƒ¨ç½²ç‹€æ…‹..."
kubectl get pods --all-namespaces
kubectl get services --all-namespaces

echo "âœ… Kubernetes æ‡‰ç”¨ç¨‹å¼é·ç§»å®Œæˆï¼"
```

## é©—è­‰å’Œæ¸¬è©¦

### é©—è­‰ EKS é·ç§»

```bash
#!/bin/bash
# verify_eks_migration.sh
source config.sh

echo "ğŸ” é©—è­‰ EKS é·ç§»ç‹€æ…‹..."

# 1. æª¢æŸ¥å¢é›†ç‹€æ…‹
echo "æª¢æŸ¥å¢é›†ç‹€æ…‹ï¼š"
aws eks describe-cluster \
  --name $CLUSTER_NAME \
  --region $TARGET_REGION \
  --query 'cluster.{Name:name,Status:status,Version:version,Endpoint:endpoint}'

# 2. æª¢æŸ¥ç¯€é»ç¾¤çµ„ç‹€æ…‹
echo "æª¢æŸ¥ç¯€é»ç¾¤çµ„ç‹€æ…‹ï¼š"
aws eks list-nodegroups \
  --cluster-name $CLUSTER_NAME \
  --region $TARGET_REGION \
  --query 'nodegroups' \
  --output text | while read nodegroup; do
    aws eks describe-nodegroup \
      --cluster-name $CLUSTER_NAME \
      --nodegroup-name $nodegroup \
      --region $TARGET_REGION \
      --query 'nodegroup.{Name:nodegroupName,Status:status,DesiredSize:scalingConfig.desiredSize,CurrentSize:scalingConfig.currentSize}'
done

# 3. æª¢æŸ¥ Pod ç‹€æ…‹
echo "æª¢æŸ¥ Pod ç‹€æ…‹ï¼š"
kubectl get pods --all-namespaces --field-selector=status.phase!=Running

# 4. æª¢æŸ¥æœå‹™ç«¯é»
echo "æª¢æŸ¥æœå‹™ç«¯é»ï¼š"
kubectl get services --all-namespaces -o wide

# 5. åŸ·è¡Œå¥åº·æª¢æŸ¥
echo "åŸ·è¡Œå¥åº·æª¢æŸ¥ï¼š"
kubectl get nodes
kubectl top nodes 2>/dev/null || echo "Metrics server æœªå®‰è£"

echo "âœ… EKS é·ç§»é©—è­‰å®Œæˆï¼"
```

## æµé‡åˆ‡æ›

### DNS æµé‡åˆ‡æ›

```bash
#!/bin/bash
# switch_dns_traffic.sh
source config.sh

SERVICE_TYPE="eks"
DOMAIN_NAME="your-domain.com"  # æ›¿æ›ç‚ºå¯¦éš›åŸŸå

echo "ğŸ”„ é–‹å§‹ DNS æµé‡åˆ‡æ›..."

# ç²å–ç›®æ¨™ç«¯é»
TARGET_ENDPOINT=$(kubectl get service -n default your-service -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')

if [[ -z "$TARGET_ENDPOINT" ]]; then
    echo "éŒ¯èª¤ï¼šç„¡æ³•ç²å–ç›®æ¨™æœå‹™ç«¯é»"
    exit 1
fi

echo "ç›®æ¨™ç«¯é»: $TARGET_ENDPOINT"

# æ¼¸é€²å¼æµé‡åˆ‡æ›ï¼ˆå¾ 10% é–‹å§‹ï¼‰
for weight in 10 25 50 75 100; do
    echo "åˆ‡æ› $weight% æµé‡åˆ° Taipei Region..."
    
    aws route53 change-resource-record-sets \
      --hosted-zone-id $HOSTED_ZONE_ID \
      --change-batch "{
        \"Changes\": [{
          \"Action\": \"UPSERT\",
          \"ResourceRecordSet\": {
            \"Name\": \"$DOMAIN_NAME\",
            \"Type\": \"CNAME\",
            \"SetIdentifier\": \"Taipei-$SERVICE_TYPE\",
            \"Weight\": $weight,
            \"TTL\": 60,
            \"ResourceRecords\": [{\"Value\": \"$TARGET_ENDPOINT\"}]
          }
        }]
      }"
    
    echo "ç­‰å¾… 2 åˆ†é˜è§€å¯Ÿæµé‡..."
    sleep 120
    
    # æª¢æŸ¥å¥åº·ç‹€æ…‹
    curl -f "http://$TARGET_ENDPOINT/health" || echo "å¥åº·æª¢æŸ¥å¤±æ•—"
done

echo "âœ… DNS æµé‡åˆ‡æ›å®Œæˆï¼"
```

## å›æ»¾ç¨‹åº

### ç·Šæ€¥å›æ»¾

```bash
#!/bin/bash
# emergency_rollback.sh
source config.sh

SERVICE_TYPE="eks"
DOMAIN_NAME="your-domain.com"

echo "ğŸš¨ åŸ·è¡Œç·Šæ€¥å›æ»¾..."

# ç«‹å³å°‡æ‰€æœ‰æµé‡åˆ‡å›ä¾†æºå€åŸŸ
aws route53 change-resource-record-sets \
  --hosted-zone-id $HOSTED_ZONE_ID \
  --change-batch "{
    \"Changes\": [{
      \"Action\": \"UPSERT\",
      \"ResourceRecordSet\": {
        \"Name\": \"$DOMAIN_NAME\",
        \"Type\": \"CNAME\",
        \"SetIdentifier\": \"Tokyo-$SERVICE_TYPE\",
        \"Weight\": 100,
        \"TTL\": 60,
        \"ResourceRecords\": [{\"Value\": \"$SOURCE_ENDPOINT\"}]
      }
    }]
  }"

echo "âœ… ç·Šæ€¥å›æ»¾å®Œæˆï¼æµé‡å·²åˆ‡å› Tokyo Region"
```

## å®Œæ•´é·ç§»è…³æœ¬

```bash
#!/bin/bash
# complete_eks_migration.sh
source common_functions.sh
load_config
validate_basic_config

echo "ğŸš€ é–‹å§‹å®Œæ•´ EKS é·ç§»æµç¨‹..."

# 1. è¨­å®š ECR è¤‡è£½ï¼ˆèƒŒæ™¯åŸ·è¡Œï¼‰
if [[ "$ECR_REPLICATION_ENABLED" == "true" ]]; then
    setup_ecr_replication &
    ECR_PID=$!
fi

# 2. é·ç§» RDS è³‡æ–™åº«ï¼ˆå¦‚æœéœ€è¦ï¼‰
if [[ "$RDS_MIGRATION_ENABLED" == "true" && -n "$DB_INSTANCE_ID" ]]; then
    migrate_rds_database &
    RDS_PID=$!
fi

# 3. åŒ¯å‡ºè¨­å®š
./export_eks_config.sh

# 4. ä¿®æ”¹è¨­å®š
./modify_eks_config.sh

# 5. éƒ¨ç½²å¢é›†
./deploy_eks_cluster.sh

# 6. é·ç§»æ‡‰ç”¨ç¨‹å¼
./migrate_k8s_apps.sh

# 7. ç­‰å¾…èƒŒæ™¯ä»»å‹™å®Œæˆ
if [[ -n "$ECR_PID" ]]; then
    wait $ECR_PID
    echo "âœ… ECR è¤‡è£½å®Œæˆ"
fi

if [[ -n "$RDS_PID" ]]; then
    wait $RDS_PID
    echo "âœ… RDS é·ç§»å®Œæˆ"
fi

# 8. é©—è­‰é·ç§»
verify_migration_status "eks"

echo "âœ… EKS é·ç§»å®Œæˆï¼"
echo "ä¸‹ä¸€æ­¥ï¼šåŸ·è¡Œæµé‡åˆ‡æ›"
echo "  ./switch_dns_traffic.sh"
```

## ä½¿ç”¨èªªæ˜

### å¿«é€Ÿé–‹å§‹

```bash
# 1. è¨­å®šç’°å¢ƒè®Šæ•¸
cp config.sh.example config.sh
# ç·¨è¼¯ config.sh å¡«å…¥å¯¦éš›å€¼

# 2. é©—è­‰è¨­å®š
./config.sh

# 3. æº–å‚™ VPC åŸºç¤è¨­æ–½
source common_functions.sh
load_config
get_vpc_resources

# 4. åŸ·è¡Œå®Œæ•´é·ç§»
./complete_eks_migration.sh

# 5. åŸ·è¡Œæµé‡åˆ‡æ›ï¼ˆå¦‚æœè¨­å®šäº† DNSï¼‰
if [[ -n "$HOSTED_ZONE_ID" ]]; then
    # ç²å– EKS æœå‹™ç«¯é»
    TARGET_ENDPOINT=$(kubectl get service -n default your-service -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
    source common_functions.sh
    switch_dns_traffic "eks" "$TARGET_ENDPOINT"
fi

# 6. å¦‚éœ€å›æ»¾
# emergency_rollback "eks" "$SOURCE_ENDPOINT"
```

### æ³¨æ„äº‹é …

1. **æ¬Šé™è¦æ±‚**ï¼šç¢ºä¿ AWS CLI å…·å‚™ EKSã€EC2ã€IAM çš„å®Œæ•´æ¬Šé™
2. **kubectl ç‰ˆæœ¬**ï¼šç¢ºä¿ kubectl ç‰ˆæœ¬èˆ‡ EKS å¢é›†ç‰ˆæœ¬ç›¸å®¹
3. **ç¶²è·¯é€£é€šæ€§**ï¼šç¢ºä¿ç›®æ¨™å€åŸŸçš„ç¶²è·¯é…ç½®æ­£ç¢º
4. **è³‡æ–™åº«é€£ç·š**ï¼šç¢ºèªæ‡‰ç”¨ç¨‹å¼èƒ½æ­£ç¢ºé€£æ¥åˆ°é·ç§»å¾Œçš„è³‡æ–™åº«
5. **ç›£æ§è¨­å®š**ï¼šé·ç§»å¾Œé‡æ–°é…ç½® CloudWatch å’Œå…¶ä»–ç›£æ§å·¥å…·

### æ•…éšœæ’é™¤

- **å¢é›†å»ºç«‹å¤±æ•—**ï¼šæª¢æŸ¥ IAM è§’è‰²æ¬Šé™å’Œ VPC é…ç½®
- **ç¯€é»ç¾¤çµ„ç„¡æ³•å•Ÿå‹•**ï¼šç¢ºèªå­ç¶²è·¯æœ‰è¶³å¤ çš„ IP åœ°å€
- **Pod ç„¡æ³•å•Ÿå‹•**ï¼šæª¢æŸ¥æ˜ åƒè·¯å¾‘å’Œç’°å¢ƒè®Šæ•¸è¨­å®š
- **æœå‹™ç„¡æ³•è¨ªå•**ï¼šé©—è­‰å®‰å…¨ç¾¤çµ„å’Œç¶²è·¯ ACL è¨­å®š

### æ¸…ç†

```bash
# æ¸…ç†æš«å­˜æª”æ¡ˆ
source common_functions.sh
cleanup_temp_files
```
